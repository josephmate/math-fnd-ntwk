
A family of random variables, indexed by time

\subsubsection{Classifications}

\paragraph{State Space} The set of possible values (states).
\paragraph{Discrete State Space} Example: the number of jobs in the system.
($S = {0,1,2,3...}$). We will only deal with the discrete case in this class. To
make notation easier the state is usually identified by the number.

\paragraph{Continuous State Space} Example: motion of a particle. We will not be
studying this in this class.

\paragraph{Time Parameter} There are two ways to observe times in Stochastic
processes.

\paragraph{Discrete Time Parameter} For example, we consider the states at
$X_0$, $X_1$, ... $X_n$. For example, looking at the state of the system
$i^{th}$ hour.

%TODO fix diagram
%\input{./diagrams/stochastic-processes/discrete-time.tex}

\paragraph{Continuous Time Parameter}
The states are function of time $t$ ($X(t)$).

\subsection{Discrete State Space and Time} There might be a dependency
between the previous time interval $X_i$'s and the states those time interval
can be in that need to be model in the current $X_n$. 
\begin{equation*} \begin{split}
	P(X_{n+1} = j | X_n = i_n\, , X_{n-1} = i_{n-1}\, , ... \, , X_1 = i_1\, ,X_0 = i_0)
\end{split} \end{equation*}
The number of dependency combinations is exponential because \\
$X_{n+1}$ depends on $X_n$ to $X_0$ \\
and $X_{n}$ depends on $X_{n-1}$ to $X_o$ \\
and so on. 

\paragraph{Markov Chain} As a result of the exponential size, we make a
simplifying assumption. We only use the latest information. $X_{n+1}$ only
depends on $X_n$. Now we are left with transition probabilities:
\begin{equation*} \begin{split}
	P(X_{n+1} | X_n) = P(X_{n+1} = j | X_n = i_n\, , X_{n-1} = i_{n-1}\, , ... \, , X_1 = i_1\, ,X_0 = i_0)
\end{split} \end{equation*}
Given $P(X_0 = i)$ for all $i$'s, we can compute any state. However, notice that
the formula depends on n, the discrete time that has pasted so far, which make
analysis difficult still. For example, in the 9am one hour interval the number
of jobs in a login system tends to be higher than at 2am.

\paragraph{Homogeneous Markov Chains} We now make the assumption that that the
transistion probabilities do not depend on time. For example, the transition
probabilies for the number of webcrawling robots requesting a webpage remain the
same despite the time. So we can write
\begin{equation*} \begin{split}
	P(X_{n+1} = j | X_n = i ) = P(X_{n} =j | X_{n-1} = i ), \forall n\,i\,j \ge 0
\end{split} \end{equation*}
Which is abbreviated to $P_{ij}$


\paragraph{State Transistion Diagram}
TODO draw diagram and place it here

\paragraph{Chapman-Kolmogorov Equation}  \label{chap-komo-eq-explain}
Let $P_{ij}^{(m)}$ be the m step transistion probability from state $i$ to $j$
defined as:
\begin{equation*} \begin{split}
	P_{ij}^{(m)} = P(X_{n+m} = j | X_n = i)
\end{split} \end{equation*}
To take m steps to go from (possibly visiting m in an intermediate state
multiple itmes), you can take m-1 to steps. At step m-1, you can arrive at any
state k. To go from each state k at the m-1 step to the m step, you just apply
the transisition probability.

We can sum the probabilities because the probabililites of going from state k in
the m-1 step to state j are mutually exclusive (they are mutually exclusive
because they are different states).

Lastly, we can mulitple the probability of going to state k in m-1 steps by the
probability of going to state j because the probabilities are independent.
\begin{equation*} \begin{split}
	P_{ij}^{(m)} = \sum_k p_{ik}^{(m-1)} p_{kj}
\end{split} \end{equation*}
Which is exactly the same as taking 1 step, and then m-1 steps.
\begin{equation*} \begin{split}
	P_{ij}^{(m)} = \sum_k p_{ik}p_{kj}^{(m-1)}
\end{split} \end{equation*}
For a derivation of this, see (\ref{chap-komo-eq-deriv}).


\paragraph{Irreducible Markov Chain} allows every state to be reached from every
other state for all pairs of states $i$ and $j$. More concretely:
\begin{equation*} \begin{split}
	\forall i \forall j \ne i : \exists m_{ij}  : P_{ij}^{(m_{ij})} > 0 
\end{split} \end{equation*}

\paragraph{Recurrent State}: State j is recurrent if after leaving state j then
you are guarenteed to eventually comeback.

Let $f_j^{(n)}$ be the probability that you first return to state j in n steps.

Notice that $f_j^{(0)} = 0$ because it's impossible to comeback without taking any
steps. Also notice that $f_j^{(1)} > 0$ is only possible is the transistion pointing
to itself $P_{jj} > 0$.

j is recurrent if and only if
\begin{equation*} \begin{split}
	f_j = \sum_{n=1}^\infty f_j^{(n)} = 1
\end{split} \end{equation*}

\paragraph{Recurrent Non-null} A state j is recurrent non-null if and only if we
get back to state j, but it does not take forever. More concretely: \\[0.5cm]
j is recurrent non-null if and only if j is recurrent ($f_j = 1$) and
\begin{equation*} \begin{split}
	M_j = \sum_{n=1}^\infty n f_j^{(n)}
\end{split} \end{equation*}
Where $M_j$ is the expected number of steps to come back.

\paragraph{Recurrent Null} j is recurrent null if and only if j is recurrent and
j is not recurrent non-null.


TODO EXAMPLE WITH DIAGRAM

TODO EXAMPLE WITH DIAGRAM

\paragraph{Periodicity} A state j is periodic if and only if the only way to
come back to state j is to take r, 2r, 3r, ... , cr, steps.  \\[0.5cm]

If a state j is not periodic, it's called aperiodic \\[0.5cm]

If state j as a self loop ($p_{jj} > 0$), then state j is aperiodic \\[0.5cm]

If the system is a irreducible Markov Chain, and contains a self loop, then all
states j are aperiodic.

\paragraph{State Probability} 
Let $X_n$ be the random variable for the state at interval n, then in a
homogeneous Markov Chain we have that:
\begin{equation*} \begin{split}
	\pi_j^{(n}) = P(X_n = j) \mbox{ - at step j }
\end{split} \end{equation*}
Let $p_{ij}$ be the transition probability for going from state $i$ to state $j$
(independant of time, so it's the same for all intervals ($X_n$), then
\begin{equation*} \begin{split}
	\pi_j^{(n+1)} = \sum_{i=0}^\infty p_{ij} \pi_i^{(n)}
	\mbox{ (by applying total probability)}
\end{split} \end{equation*}

Given initial conditions $\pi_j^{(0)} \forall j$, we can compute all
$\pi_j^{(i)}$ apply the above formula recursively.

\paragraph{Equilibrium Probability Therom} (I made up this name. It seems better
than 'Fundamental Theorm.)

If a homogeneous Markov Chain is irreducible and a periodic, then there exists a
limiting probability (equilibrium):
\begin{equation*} \begin{split}
	\pi_j = \lim_{n \to \infty} \pi_j^{(n)}
\end{split} \end{equation*}
which is independant of the initial conditions $\pi_j^{(0)}$. \\[0.5cm]

Moreover, if all states j are recurrent non-null, then $\pi_j$ is non zero and
can be uniquely etermined from the equations:
\begin{equation*} \begin{split}
	\pi_j = \sum_i p_{ij} \pi_i , \forall j
\end{split} \end{equation*}
\begin{equation*} \begin{split}
	\sum_j \pi_j = 1
\end{split} \end{equation*}

\subparagraph{Example}
\begin{figure}[!h]
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,on grid,auto,node distance=3cm,
  thick,main node/.style={circle,fill=white!20,draw,font=\sffamily\Large\bfseries}]

  \node[main node] (1) {1};
  \node[main node] (2) [below left of=1] {2};
  \node[main node] (3) [below right of=1] {3};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge [bend right=15] node {.75} (2)
        edge [bend left=30]  node {.25} (3)
    (2) edge [bend left=30]  node {.25} (1)
        edge [bend right=15] node {.75} (3)
    (3) edge [bend left=30]  node {.25} (2)
        edge [bend right=15] node {.25} (1);
\end{tikzpicture}
\end{figure}
\begin{figure}[!h]
Let the initial state be (1). This is the 'initial condition'
\begin{tabular}{ r | r  | r  |  r  |  r  |  r  |  r   | r }
	  n & 0 & 1  & 2  & 3  & 4  & ...  & $\infty$ \\
	\hline
	$\pi_1^{(n)})$ & 1 & 0    & .25   & .187  & .203  &  & .2 \\
	$\pi_2^{(n)})$ & 0 & .25  & .062  & .359  & .254  &  & .28 \\
	$\pi_3^{(n)})$ & 0 & .75  & .688  & .454  & .543  &  & .52 \\
\end{tabular}
\end{figure}
\begin{figure}[!h]
To get the steady state column, you have to solve the system of equations that
results from the above theorm. From the table we can see that the emperical
basis for this theorm. As you compute more columns, it approaches the values
computed from the steady state equations.
\end{figure}

\begin{equation*} \begin{split}
\end{split} \end{equation*}

\paragraph{Memoryless Property}, the residence time in a state.













